# RL-exercise           [ In construnction]  
The exercise follow David Silver lecture

branch master


一.Model Based



-1.Implement Policy Evaluation in Python (Gridworld)



-2.Implement Policy Iteration in Python (Gridworld)



-3.Implement Value Iteration in Python (Gridworld)


-4.To do Implement Gambler's Problem



二.Model Free

-1. Model-Free Monte Carlo Prediction & Control

(MC)

--1.1 Every visit MC Predection for V(s)

--1.2 GELIE epsilon greedy MC Contorl for Q(s,a)

--1.3 To Do Implement the off-policy every-visit Monte Carlo Control using Weighted Important Sampling algorithm (Importance Sampling does not work frequently)


-2. Model-Free Prediction & Control with Temporal Difference (TD) and Q-Learning

(TD)

--2.1 SARSA(0) by GELIE Epsilon greedy

--2.2 Q learning with MAX SARSA

--2.3 TO DO ,TD(lambda with eligibity trace)

-3.Value Functin approximation

（Value_approx）

--3.1 SGD linear Q value fucion approximator with Q learning


-4.Deep Q Network

--4.1 Deep Q learning (maze,run,Network)

--4.2 Deep Q learning(image input DQN.py)
